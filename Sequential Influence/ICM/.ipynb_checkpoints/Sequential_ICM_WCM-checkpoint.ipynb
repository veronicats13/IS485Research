{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Influence Spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Influence Spread Using Independent Cascade Model (Weighted Cascade Model)\n",
    "\n",
    "- Build 'Policy Tree' Reference\n",
    "- Run Actual Influence Spread that checks reference to attain highest long term potential reward\n",
    "- Experiment to evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build 'Policy Tree' Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import ModelConfig as mc\n",
    "# import IndependentCascadesModelP001 as icm\n",
    "# import IndependentCascadesModelP010 as icm\n",
    "import WeightedCascadeModel as icm\n",
    "import operator\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Simulation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GreedySelect(g, activated_nodes, model, config, greedy_i):\n",
    "    ''' \n",
    "    Select node with highest average marginal gain\n",
    "    Variable 'mg' refers to 'marginal gain'\n",
    "    '''\n",
    "    mg_dict = {}\n",
    "    for candidate in g.nodes():\n",
    "        if candidate in activated_nodes:\n",
    "            continue\n",
    "        mg = 0\n",
    "        for i in range(greedy_i):\n",
    "            newly_activated_nodes = GreedySim(model, config, candidate)\n",
    "            mg += len(newly_activated_nodes)\n",
    "        avg_mg = mg/greedy_i\n",
    "        mg_dict[candidate] = avg_mg\n",
    "    influencer = max(mg_dict.items(), key=operator.itemgetter(1))[0]\n",
    "    print(f\"Selected Influencer: Node {influencer}\")\n",
    "    \n",
    "    return influencer\n",
    "\n",
    "def GreedySim(model, config, candidate):\n",
    "    ''' \n",
    "    Greedy Simulation to test the influence spread of a given node candidate\n",
    "    Returns a list of nodes that were activated by the candidate\n",
    "    '''\n",
    "    config.add_model_initial_configuration(\"Infected\", [candidate])\n",
    "    model.set_initial_status(config)\n",
    "    active_set_size, newly_activated_nodes = model.iteration_bunch()\n",
    "    newly_activated_nodes.append(candidate)\n",
    "    model.mg_reset(newly_activated_nodes)\n",
    "    \n",
    "    return newly_activated_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitModel(g):\n",
    "    '''\n",
    "    Initializes Diffusion Model (Independent Cascade Model)\n",
    "    Instantiates its configuration\n",
    "    '''\n",
    "    model = icm.IndependentCascadesModel(g)\n",
    "    config = mc.Configuration()\n",
    "    return model, config\n",
    "\n",
    "def InfluenceSpread(model, config, influencer):\n",
    "    '''\n",
    "    Runs influence spread for the given target set\n",
    "    Returns its active set size\n",
    "    '''\n",
    "    config.add_model_initial_configuration(\"Infected\", [influencer])\n",
    "    model.set_initial_status(config)\n",
    "    active_set_size, newly_activated_nodes = model.iteration_bunch()\n",
    "    return active_set_size, newly_activated_nodes\n",
    "\n",
    "def get_combination(g, target_set_size, greedy_i=100):\n",
    "    '''\n",
    "    Assuming continuous process (previously activated nodes cannot reattempt)\n",
    "    As compared to one-time influence spread, all influencer same start point\n",
    "    Default strategy set as greedy \n",
    "    '''\n",
    "    g = remove_isolated_nodes(g)\n",
    "    model, config = InitModel(g)\n",
    "    \n",
    "    all_activated_nodes = []\n",
    "    influencers = []\n",
    "    active_ss_list = []\n",
    "    for i in range(1, target_set_size+1):\n",
    "        print(f\"Selecting Influencer {i}\")\n",
    "        print(\"------------------------------------\")\n",
    "        \n",
    "        influencer = GreedySelect(g, all_activated_nodes, model, config, greedy_i)\n",
    "        influencers.append(influencer)\n",
    "\n",
    "        active_set_size, newly_activated_nodes = InfluenceSpread(model, config, influencer)\n",
    "        print(f\"Newly Activated Nodes: {newly_activated_nodes}\")\n",
    "        newly_activated_nodes.append(influencer)\n",
    "        all_activated_nodes.extend(newly_activated_nodes)\n",
    "        print(f\"All Activated Nodes: {all_activated_nodes}\")\n",
    "        print(f\"Active Set Size: {active_set_size}\")\n",
    "        \n",
    "        active_set_size, all_activated_nodes = model.random_deactivation(all_activated_nodes)\n",
    "        print(f\"Final Activated Nodes: {all_activated_nodes}\")\n",
    "        print(f\"Final Active Set Size: {active_set_size}\")\n",
    "        print(\"\")\n",
    "\n",
    "        model.is_reset()\n",
    "        active_ss_list.append(active_set_size)\n",
    "\n",
    "    return influencers, active_ss_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_isolated_nodes(g):\n",
    "    '''\n",
    "    Returns given graph with no isolated node\n",
    "    '''\n",
    "    isolated_nodes = []\n",
    "    for pair in g.degree:\n",
    "        node = pair[0]\n",
    "        degree = pair[1]\n",
    "        if degree == 0:\n",
    "            isolated_nodes.append(node)\n",
    "\n",
    "    for node in isolated_nodes:\n",
    "        g.remove_node(node)\n",
    "        \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare Graph\n",
    "'''\n",
    "nx.erdos_renyi_graph(number of nodes, probability to form edges) \n",
    "'''\n",
    "g = nx.erdos_renyi_graph(150, 0.1) \n",
    "g = remove_isolated_nodes(g)\n",
    "\n",
    "# 'Policy Tree' Reference Settings\n",
    "'''\n",
    "target_set_size: The number of influencers to be selected (constant throughout the process)\n",
    "greedy_i: The number of times greedy simulation is executed (Greedy Iteration)\n",
    "num_i: The number of times the function get_combination() is repeated to get as many high reward combinations as possible \n",
    "LT_ref: A sorted list containing tuple ([influencers], LT_reward)\n",
    "sorted_influencers: A list containing influencers from LT_ref\n",
    "'''\n",
    "target_set_size = 5\n",
    "greedy_i = 50\n",
    "LT_ref = []\n",
    "num_i = 100\n",
    "for i in range(1, num_i+1):\n",
    "    print(f\"Combination {i}\")\n",
    "    print(\"------------------------------------\")\n",
    "        \n",
    "    combination = get_combination(g, target_set_size, greedy_i)\n",
    "    LT_ref.append(combination)\n",
    "\n",
    "LT_ref.sort(key=lambda x:x[1], reverse=True)\n",
    "sorted_influencers = []\n",
    "for influencers, LT_reward in LT_ref:\n",
    "    if influencers in sorted_influencers:\n",
    "        continue  \n",
    "    sorted_influencers.append(influencers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LT_ref)\n",
    "print(\"\")\n",
    "print(sorted_influencers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Actual Influence Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_reference(sorted_influencers, all_activated_nodes, i, model, config):\n",
    "    '''\n",
    "    Check 'Policy Tree' reference to determine next influencer\n",
    "    Assign influencer to the node in the top combination (highest LT reward)\n",
    "    If it is already activated, selected another node in the next best matching combination\n",
    "    Otherwise, if no matching combination, run greedy \n",
    "    - wish to avoid this as much as possible especially for large graphs so best to prepare adequate combinations\n",
    "    Lastly, filter sorted influencers for unmatching combinations\n",
    "    '''\n",
    "    influencer = sorted_influencers[0][i]\n",
    "    j = 1\n",
    "    while influencer in all_activated_nodes:\n",
    "        try:   \n",
    "            influencer = sorted_influencers[j][i]\n",
    "            j += 1\n",
    "        except IndexError:\n",
    "            influencer = GreedySelect(g, all_activated_nodes, model, config, greedy_i)\n",
    "\n",
    "    print(f\"Influencer: Node {influencer}\")\n",
    "    n = []\n",
    "    for combination in sorted_influencers:\n",
    "        if combination[i] == influencer:\n",
    "            n.append(combination)\n",
    "    print(f\"New Sorted Combination List: {n}\")\n",
    "    sorted_influencers = n\n",
    "    return influencer, sorted_influencers\n",
    "\n",
    "def greedy_sequential(g, target_set_size, greedy_i, sorted_influencers):\n",
    "    '''\n",
    "    Initialize Model\n",
    "    Select Influencer Greedily \n",
    "    - LT Reward Reference, or ST Reward Marginal Gain\n",
    "    Run Influence Spread\n",
    "    Execute Random Deactivation\n",
    "    '''\n",
    "    g = remove_isolated_nodes(g)\n",
    "    model, config = InitModel(g)\n",
    "    \n",
    "    all_activated_nodes = []\n",
    "    influencers = []\n",
    "    active_ss_list = []\n",
    "    \n",
    "    for i in range(target_set_size):\n",
    "        print(f\"Selecting Influencer {i+1}\")\n",
    "        print(\"------------------------------------\")\n",
    "        \n",
    "        if sorted_influencers == []: # If no matching combination, simulate greedy\n",
    "            influencer = GreedySelect(g, all_activated_nodes, model, config, greedy_i)\n",
    "            print(\"Approach: Greedy Select\")\n",
    "        else: # Check LT Reward Reference\n",
    "            influencer, sorted_influencers = check_reference(sorted_influencers, all_activated_nodes, i, model, config)\n",
    "            print(\"Approach: LT Reward Reference\")\n",
    "            \n",
    "        influencers.append(influencer)\n",
    "\n",
    "        active_set_size, newly_activated_nodes = InfluenceSpread(model, config, influencer)\n",
    "        print(f\"Newly Activated Nodes: {newly_activated_nodes}\")\n",
    "        newly_activated_nodes.append(influencer)\n",
    "        all_activated_nodes.extend(newly_activated_nodes)\n",
    "        print(f\"All Activated Nodes: {all_activated_nodes}\")\n",
    "        print(f\"Active Set Size: {active_set_size}\")\n",
    "        \n",
    "        active_set_size, all_activated_nodes = model.random_deactivation(all_activated_nodes)\n",
    "        print(f\"Final Activated Nodes: {all_activated_nodes}\")\n",
    "        print(f\"Final Active Set Size: {active_set_size}\")\n",
    "        print(\"\")\n",
    "\n",
    "        model.is_reset()\n",
    "        active_ss_list.append(active_set_size)\n",
    "\n",
    "    return influencers, active_ss_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Experiment Settings for Adaptive Greedy \n",
    "'''\n",
    "exp_i: Experiment Iterations, the number of times the experiment is repeated in order to get the average activated nodes\n",
    "'''\n",
    "exp_i = 20\n",
    "greedy_i = 50\n",
    "target_set_size = 5\n",
    "g_total_activated_nodes = 0\n",
    "\n",
    "for i in range(exp_i):\n",
    "    influencers, active_set_size = greedy_sequential(g, target_set_size, greedy_i, sorted_influencers)\n",
    "    g_total_activated_nodes += active_set_size\n",
    "\n",
    "g_avg_activated_nodes = g_total_activated_nodes / exp_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Experiment by comparing to baseline (Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sequential(g, target_set_size):\n",
    "    '''\n",
    "    Initialize Model\n",
    "    Select Influencer Randomly \n",
    "    Run Influence Spread\n",
    "    Execute Random Deactivation\n",
    "    '''\n",
    "    g = remove_isolated_nodes(g)\n",
    "    model, config = InitModel(g)\n",
    "    \n",
    "    all_activated_nodes = []\n",
    "    influencers = []\n",
    "    active_ss_list = []\n",
    "    \n",
    "    for i in range(target_set_size):\n",
    "        print(f\"Selecting Influencer {i+1}\")\n",
    "        print(\"------------------------------------\")\n",
    "        \n",
    "        influencer = random.randint(0, len(g)-1)\n",
    "        while influencer in all_activated_nodes:\n",
    "            influencer = random.randint(0, len(g)-1)\n",
    "        print(f\"Influencer: Node {influencer}\")\n",
    "            \n",
    "        influencers.append(influencer)\n",
    "\n",
    "        active_set_size, newly_activated_nodes = InfluenceSpread(model, config, influencer)\n",
    "        print(f\"Newly Activated Nodes: {newly_activated_nodes}\")\n",
    "        newly_activated_nodes.append(influencer)\n",
    "        all_activated_nodes.extend(newly_activated_nodes)\n",
    "        print(f\"All Activated Nodes: {all_activated_nodes}\")\n",
    "        print(f\"Active Set Size: {active_set_size}\")\n",
    "        \n",
    "        active_set_size, all_activated_nodes = model.random_deactivation(all_activated_nodes)\n",
    "        print(f\"Final Activated Nodes: {all_activated_nodes}\")\n",
    "        print(f\"Final Active Set Size: {active_set_size}\")\n",
    "        print(\"\")\n",
    "\n",
    "        model.is_reset()\n",
    "        active_ss_list.append(active_set_size)\n",
    "\n",
    "    return influencers, active_ss_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Settings for Random\n",
    "'''\n",
    "exp_i: Experiment Iterations, the number of times the experiment is repeated in order to get the average activated nodes\n",
    "'''\n",
    "exp_i = 20\n",
    "target_set_size = 5\n",
    "r_total_activated_nodes = 0\n",
    "\n",
    "for i in range(exp_i):\n",
    "    influencers, active_set_size = random_sequential(g, target_set_size)\n",
    "    r_total_activated_nodes += active_set_size\n",
    "\n",
    "r_avg_activated_nodes = r_total_activated_nodes / exp_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_avg_activated_nodes)\n",
    "print(r_avg_activated_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
